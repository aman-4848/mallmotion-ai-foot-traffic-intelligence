# Mall Movement Tracking - ML Project

A comprehensive machine learning project for tracking and analyzing customer movement patterns in shopping malls. This project includes feature engineering, classification, clustering, forecasting models, and interactive dashboards.

## ğŸ¯ Project Overview

This project analyzes customer movement data to:
- **Predict next zone visits** using classification models
- **Cluster customer behavior patterns** using unsupervised learning
- **Forecast traffic patterns** using time series models
- **Visualize insights** through interactive Streamlit dashboards
- **Serve predictions** via FastAPI endpoints

## ğŸ“ Project Structure

```
mall-movement-tracking/
â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”œâ”€â”€ app.py              # Main API application
â”‚   â”œâ”€â”€ routers/            # API route handlers
â”‚   â”œâ”€â”€ schemas/            # Pydantic models
â”‚   â””â”€â”€ services/           # Business logic
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ project_config.yaml
â”‚   â””â”€â”€ secrets_template.yaml
â”œâ”€â”€ data/                   # Data storage
â”‚   â”œâ”€â”€ processed/         # Cleaned and processed data
â”‚   â””â”€â”€ sample/            # Sample data files
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ api_docs.md
â”‚   â”œâ”€â”€ data_dictionary.md
â”‚   â””â”€â”€ model_cards/        # Model documentation
â”œâ”€â”€ features/               # Feature engineering
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ feature_config.yaml
â”‚   â””â”€â”€ run_feature_engineering.py
â”œâ”€â”€ models/                 # Trained models
â”‚   â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ clustering/
â”‚   â””â”€â”€ forecasting/
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_EDA.ipynb       # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_Feature_Analysis.ipynb
â”‚   â”œâ”€â”€ 03_Modeling_Experiments.ipynb
â”‚   â””â”€â”€ 04_Model_Comparison.ipynb
â”œâ”€â”€ results/                # Model results and metrics
â”œâ”€â”€ streamlit_app/         # Streamlit dashboard
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ pages/             # Dashboard pages
â”œâ”€â”€ training/              # Training scripts
â”‚   â”œâ”€â”€ train_classification.py
â”‚   â”œâ”€â”€ train_clustering.py
â”‚   â””â”€â”€ train_forecasting.py
â””â”€â”€ tests/                  # Unit tests
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- pip or conda

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/mall-movement-tracking.git
cd mall-movement-tracking
```

2. **Create virtual environment**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Prepare data**
   - Place your processed data in `data/processed/merged data set.csv`
   - Or use the existing processed data

5. **Run feature engineering**
```bash
python features/run_feature_engineering.py
```

6. **Train models**
```bash
# Train classification models
python training/train_classification.py

# Train clustering models
python training/train_clustering.py

# Train forecasting models
python training/train_forecasting.py
```

7. **Run Streamlit dashboard**
```bash
streamlit run streamlit_app/app.py
```

8. **Run API server**
```bash
cd api
uvicorn app:app --reload
```

## ğŸ“Š Features

### Feature Engineering
- âœ… Missing value handling
- âœ… Categorical encoding (label & one-hot)
- âœ… Datetime feature extraction
- âœ… Outlier detection & handling
- âœ… Binning/grouping
- âœ… Domain-specific features
- âœ… Column combining

### Models
- **Classification**: Random Forest, Decision Tree, XGBoost
- **Clustering**: K-Means, DBSCAN
- **Forecasting**: ARIMA, Prophet

### Dashboards
- Data Explorer
- Heatmaps
- Classification Results
- Clustering Insights
- Forecasting Traffic
- Next Zone Prediction
- Model Explainability

## ğŸ“– Usage

### Running Notebooks

1. **EDA Analysis**
```bash
jupyter notebook notebooks/01_EDA.ipynb
```

2. **Feature Analysis**
```bash
jupyter notebook notebooks/02_Feature_Analysis.ipynb
```

### API Endpoints

Once the API is running, access:
- `http://localhost:8000/` - API root
- `http://localhost:8000/docs` - Interactive API documentation
- `http://localhost:8000/api/data/info` - Dataset information
- `http://localhost:8000/api/results/classification` - Classification results
- `http://localhost:8000/api/results/clustering` - Clustering results
- `http://localhost:8000/api/results/forecasting` - Forecasting results

## ğŸ› ï¸ Configuration

Edit `features/feature_config.yaml` to customize feature engineering:
- Missing value handling strategy
- Encoding methods
- Outlier detection methods
- Binning parameters
- Domain-specific features

## ğŸ“ Workflow

1. **Exploratory Data Analysis** â†’ `notebooks/01_EDA.ipynb`
2. **Feature Engineering** â†’ `notebooks/02_Feature_Analysis.ipynb` or `features/run_feature_engineering.py`
3. **Model Training** â†’ `training/train_*.py` scripts
4. **Visualization** â†’ Streamlit dashboard
5. **API** â†’ FastAPI endpoints

## ğŸ§ª Testing

Run tests:
```bash
pytest tests/
```

## ğŸ“š Documentation

- [API Documentation](docs/api_docs.md)
- [Data Dictionary](docs/data_dictionary.md)
- [Model Cards](docs/model_cards/)
- [Feature Engineering Guide](features/README.md)
- [Workflow Guide](WORKFLOW.md)
- [GitHub Setup Guide](GITHUB_SETUP.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

Your Name - [GitHub Profile](https://github.com/YOUR_USERNAME)

## ğŸ™ Acknowledgments

- Libraries: pandas, scikit-learn, xgboost, streamlit, fastapi
- Data sources: [Your data source]

## ğŸ“§ Contact

For questions or suggestions, please open an issue or contact [your-email@example.com]

---

**Note**: This project uses processed/cleaned data. Large data files and model files (.pkl) are excluded from the repository. Make sure to have your data in `data/processed/` before running the project.

