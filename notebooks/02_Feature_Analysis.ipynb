{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdf05b91",
   "metadata": {},
   "source": [
    "# Feature Analysis and Engineering\n",
    "## Mall Movement Tracking Dataset\n",
    "\n",
    "This notebook performs comprehensive feature engineering and analysis:\n",
    "- Feature engineering pipeline\n",
    "- Feature selection\n",
    "- Feature importance analysis\n",
    "- Before/after comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e909c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Project root: C:\\Users\\hp\\Desktop\\mall-movement-tracking ml\n",
      "Python path includes: C:\\Users\\hp\\Desktop\\mall-movement-tracking ml\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve()\n",
    "# If we're in notebooks folder, go up one level to project root\n",
    "if project_root.name == 'notebooks':\n",
    "    project_root = project_root.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import modules\n",
    "from streamlit_app.utils.data_loader import load_processed_data\n",
    "from features.feature_engineering import FeatureEngineer\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path includes: {str(project_root)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5b319",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b4e4f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "============================================================\n",
      "Shape: (15839, 80)\n",
      "Columns: 80\n",
      "\n",
      "Column names:\n",
      "   1. USERID (int64)\n",
      "   2. TIMESTAMP (int64)\n",
      "   3. WAP011 (int64)\n",
      "   4. WAP012 (int64)\n",
      "   5. WAP051 (int64)\n",
      "   6. WAP052 (int64)\n",
      "   7. WAP059 (int64)\n",
      "   8. WAP060 (int64)\n",
      "   9. WAP061 (int64)\n",
      "  10. WAP062 (int64)\n",
      "  11. WAP063 (int64)\n",
      "  12. WAP064 (int64)\n",
      "  13. WAP065 (int64)\n",
      "  14. WAP066 (int64)\n",
      "  15. WAP069 (int64)\n",
      "  16. WAP070 (int64)\n",
      "  17. WAP073 (int64)\n",
      "  18. WAP074 (int64)\n",
      "  19. WAP077 (int64)\n",
      "  20. WAP078 (int64)\n",
      "  21. WAP082 (int64)\n",
      "  22. WAP083 (int64)\n",
      "  23. WAP084 (int64)\n",
      "  24. WAP085 (int64)\n",
      "  25. WAP087 (int64)\n",
      "  26. WAP096 (int64)\n",
      "  27. WAP097 (int64)\n",
      "  28. WAP098 (int64)\n",
      "  29. WAP099 (int64)\n",
      "  30. WAP117 (int64)\n",
      "  31. WAP118 (int64)\n",
      "  32. WAP121 (int64)\n",
      "  33. WAP122 (int64)\n",
      "  34. WAP127 (int64)\n",
      "  35. WAP128 (int64)\n",
      "  36. WAP131 (int64)\n",
      "  37. WAP132 (int64)\n",
      "  38. WAP144 (int64)\n",
      "  39. WAP145 (int64)\n",
      "  40. WAP155 (int64)\n",
      "  41. WAP156 (int64)\n",
      "  42. WAP161 (int64)\n",
      "  43. WAP162 (int64)\n",
      "  44. WAP248 (int64)\n",
      "  45. WAP277 (int64)\n",
      "  46. WAP332 (int64)\n",
      "  47. WAP389 (int64)\n",
      "  48. WAP478 (int64)\n",
      "  49. WAP489 (int64)\n",
      "  50. WAP495 (int64)\n",
      "  51. WAP496 (int64)\n",
      "  52. WAP501 (int64)\n",
      "  53. WAP502 (int64)\n",
      "  54. WAP516 (int64)\n",
      "  55. WAP517 (int64)\n",
      "  56. LONGITUDE (float64)\n",
      "  57. LATITUDE (float64)\n",
      "  58. FLOOR (int64)\n",
      "  59. BUILDINGID (int64)\n",
      "  60. SPACEID (int64)\n",
      "  61. RELATIVEPOSITION (int64)\n",
      "  62. PHONEID (int64)\n",
      "  63. WAP013 (int64)\n",
      "  64. WAP014 (int64)\n",
      "  65. WAP035 (int64)\n",
      "  66. WAP036 (int64)\n",
      "  67. WAP041 (int64)\n",
      "  68. WAP042 (int64)\n",
      "  69. WAP067 (int64)\n",
      "  70. WAP068 (int64)\n",
      "  71. WAP138 (int64)\n",
      "  72. WAP139 (int64)\n",
      "  73. WAP203 (int64)\n",
      "  74. WAP204 (int64)\n",
      "  75. WAP503 (int64)\n",
      "  76. path (float64)\n",
      "  77. modificationTime (float64)\n",
      "  78. length (float64)\n",
      "  79. content (float64)\n",
      "  80. filename (float64)\n"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "df_original = load_processed_data()\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df_original.shape}\")\n",
    "print(f\"Columns: {len(df_original.columns)}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for i, col in enumerate(df_original.columns, 1):\n",
    "    print(f\"  {i:2d}. {col} ({df_original[col].dtype})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a9406a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767195bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "fe = FeatureEngineer()\n",
    "\n",
    "# Detect column types\n",
    "column_types = fe.detect_column_types(df_original)\n",
    "\n",
    "print(\"Detected Column Types:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Datetime columns: {column_types['datetime']}\")\n",
    "print(f\"Categorical columns: {column_types['categorical']}\")\n",
    "print(f\"Numeric columns: {column_types['numeric']}\")\n",
    "print(f\"ID columns: {column_types['id']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f2a07",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f780d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handle Missing Values\n",
    "print(\"Step 1: Handling Missing Values...\")\n",
    "df_step1 = fe.handle_missing_values(df_original.copy(), strategy='auto')\n",
    "missing_before = df_original.isnull().sum().sum()\n",
    "missing_after = df_step1.isnull().sum().sum()\n",
    "print(f\"  Missing values before: {missing_before:,}\")\n",
    "print(f\"  Missing values after: {missing_after:,}\")\n",
    "print(f\"  âœ“ Missing values handled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeadfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ac93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723543a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355dbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b860ce9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40288d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8079ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702604d7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96accebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7d409",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e905bd",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3644bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85283aa9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numeric features\n",
    "if len(numeric_features) > 1:\n",
    "    # Select top features for correlation (to avoid too large matrix)\n",
    "    top_features = numeric_features[:15] if len(numeric_features) > 15 else numeric_features\n",
    "    corr_matrix = df_engineered[top_features].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix of Engineered Features (Top 15)', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated pairs\n",
    "    print(\"\\nHighly Correlated Feature Pairs (|correlation| > 0.7):\")\n",
    "    print(\"=\"*60)\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_val = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.7:\n",
    "                high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_val))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        for col1, col2, corr in high_corr_pairs[:10]:  # Show top 10\n",
    "            print(f\"{col1:30s} <-> {col2:30s} : {corr:6.3f}\")\n",
    "    else:\n",
    "        print(\"No highly correlated pairs found.\")\n",
    "else:\n",
    "    print(\"Need at least 2 numeric features for correlation analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8da3a7c",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Using Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2846f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to identify target column for feature importance\n",
    "zone_cols = [col for col in df_engineered.columns if 'zone' in col.lower() or 'location' in col.lower()]\n",
    "target_col = zone_cols[0] if zone_cols else None\n",
    "\n",
    "if target_col and target_col in df_engineered.columns:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df_engineered[numeric_features].fillna(0)\n",
    "    y = df_engineered[target_col]\n",
    "    \n",
    "    # Encode target if categorical\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "    \n",
    "    # Train random forest for feature importance\n",
    "    print(\"Training Random Forest for Feature Importance...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': numeric_features,\n",
    "        'Importance': rf.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 20 Most Important Features:\")\n",
    "    print(\"=\"*60)\n",
    "    display(feature_importance.head(20))\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'].values, color='steelblue')\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'].values)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 20 Feature Importance (Random Forest)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Target column not found. Skipping feature importance analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1bf87",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered features\n",
    "output_path = Path().resolve().parent / \"data\" / \"processed\" / \"engineered_features.csv\"\n",
    "df_engineered.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Engineered features saved to: {output_path}\")\n",
    "print(f\"Shape: {df_engineered.shape}\")\n",
    "print(f\"Columns: {len(df_engineered.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e804d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
