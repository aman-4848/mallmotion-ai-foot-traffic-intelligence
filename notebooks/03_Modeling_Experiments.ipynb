{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785ef41b",
   "metadata": {},
   "source": [
    "# Modeling Experiments\n",
    "## Mall Movement Tracking - ML Model Training and Comparison\n",
    "\n",
    "This notebook performs comprehensive ML model training experiments:\n",
    "- Classification models (Random Forest, Decision Tree, XGBoost)\n",
    "- Clustering models (K-Means, DBSCAN)\n",
    "- Forecasting models (ARIMA, Prophet)\n",
    "- Model comparison and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, classification_report, \n",
    "                             confusion_matrix, roc_auc_score, silhouette_score,\n",
    "                             mean_squared_error, mean_absolute_error)\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve()\n",
    "if project_root.name == 'notebooks':\n",
    "    project_root = project_root.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project modules\n",
    "from streamlit_app.utils.data_loader import load_processed_data\n",
    "from features.feature_engineering import FeatureEngineer\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Project root: {project_root}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373319",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "print(\"Loading processed data...\")\n",
    "df_original = load_processed_data()\n",
    "print(f\"Original data shape: {df_original.shape}\")\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"\\nApplying feature engineering...\")\n",
    "fe = FeatureEngineer()\n",
    "df = fe.engineer_features(df_original)\n",
    "print(f\"Engineered data shape: {df.shape}\")\n",
    "print(f\"New features created: {len(df.columns) - len(df_original.columns)}\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nData Summary:\")\n",
    "print(f\"  - Rows: {len(df):,}\")\n",
    "print(f\"  - Columns: {len(df.columns)}\")\n",
    "print(f\"  - Missing values: {df.isnull().sum().sum():,}\")\n",
    "print(f\"  - Numeric columns: {len(df.select_dtypes(include=[np.number]).columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce52def",
   "metadata": {},
   "source": [
    "## 2. Classification Models - Zone Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dcdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for classification\n",
    "print(\"=\" * 60)\n",
    "print(\"CLASSIFICATION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Auto-detect target column\n",
    "zone_cols = [col for col in df.columns if 'zone' in col.lower() or 'location' in col.lower() or 'space' in col.lower()]\n",
    "target_col = zone_cols[0] if zone_cols else df.columns[-1]\n",
    "\n",
    "print(f\"\\nTarget column: {target_col}\")\n",
    "print(f\"Unique values: {df[target_col].nunique()}\")\n",
    "\n",
    "# Select features\n",
    "exclude_cols = ['target', target_col] + [col for col in df.columns if df[col].dtype == 'object']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols and df[col].dtype in [np.number]]\n",
    "\n",
    "print(f\"\\nFeature columns: {len(feature_cols)}\")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df[target_col]\n",
    "\n",
    "# Encode target if categorical\n",
    "if y.dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    y = y_encoded\n",
    "    print(f\"Target encoded: {len(le.classes_)} classes\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Training Random Forest...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "if len(np.unique(y_test)) > 2:\n",
    "    rf_roc_auc = roc_auc_score(y_test, rf_pred_proba, multi_class='ovr')\n",
    "else:\n",
    "    rf_roc_auc = roc_auc_score(y_test, rf_pred_proba[:, 1])\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Random Forest ROC-AUC: {rf_roc_auc:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Important Features:\")\n",
    "display(rf_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Training Decision Tree...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Training XGBoost...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "if len(np.unique(y_test)) > 2:\n",
    "    xgb_roc_auc = roc_auc_score(y_test, xgb_pred_proba, multi_class='ovr')\n",
    "else:\n",
    "    xgb_roc_auc = roc_auc_score(y_test, xgb_pred_proba[:, 1])\n",
    "\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(f\"XGBoost ROC-AUC: {xgb_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ded00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Results Summary\n",
    "classification_results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Decision Tree', 'XGBoost'],\n",
    "    'Accuracy': [rf_accuracy, dt_accuracy, xgb_accuracy],\n",
    "    'ROC-AUC': [rf_roc_auc, np.nan, xgb_roc_auc]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLASSIFICATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "display(classification_results)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(classification_results['Model'], classification_results['Accuracy'], \n",
    "           color=['steelblue', 'coral', 'lightgreen'], alpha=0.7)\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Classification Model Accuracy Comparison')\n",
    "axes[0].set_ylim([0, 1])\n",
    "for i, v in enumerate(classification_results['Accuracy']):\n",
    "    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# ROC-AUC comparison\n",
    "roc_data = classification_results[classification_results['ROC-AUC'].notna()]\n",
    "axes[1].bar(roc_data['Model'], roc_data['ROC-AUC'], \n",
    "           color=['steelblue', 'lightgreen'], alpha=0.7)\n",
    "axes[1].set_ylabel('ROC-AUC')\n",
    "axes[1].set_title('Classification Model ROC-AUC Comparison')\n",
    "axes[1].set_ylim([0, 1])\n",
    "for i, v in enumerate(roc_data['ROC-AUC']):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef1681",
   "metadata": {},
   "source": [
    "## 3. Clustering Models - Customer Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for clustering\n",
    "print(\"=\" * 60)\n",
    "print(\"CLUSTERING MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select numeric features\n",
    "clustering_features = [col for col in df.columns if df[col].dtype in [np.number]]\n",
    "X_cluster = df[clustering_features].fillna(0)\n",
    "\n",
    "print(f\"\\nFeatures for clustering: {len(clustering_features)}\")\n",
    "print(f\"Data shape: {X_cluster.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Training K-Means...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "n_clusters = 5\n",
    "kmeans_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans_model.fit_predict(X_scaled)\n",
    "\n",
    "kmeans_silhouette = silhouette_score(X_scaled, kmeans_labels)\n",
    "\n",
    "print(f\"K-Means Clusters: {n_clusters}\")\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette:.4f}\")\n",
    "print(f\"Cluster distribution:\")\n",
    "for i in range(n_clusters):\n",
    "    count = np.sum(kmeans_labels == i)\n",
    "    print(f\"  Cluster {i}: {count:,} customers ({count/len(kmeans_labels)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DBSCAN\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Training DBSCAN...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "dbscan_model = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan_model.fit_predict(X_scaled)\n",
    "\n",
    "n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"DBSCAN Clusters found: {n_clusters_dbscan}\")\n",
    "print(f\"Noise points: {n_noise:,} ({n_noise/len(dbscan_labels)*100:.1f}%)\")\n",
    "\n",
    "if n_clusters_dbscan > 1:\n",
    "    dbscan_silhouette = silhouette_score(X_scaled, dbscan_labels)\n",
    "    print(f\"DBSCAN Silhouette Score: {dbscan_silhouette:.4f}\")\n",
    "else:\n",
    "    dbscan_silhouette = -1\n",
    "    print(\"DBSCAN Silhouette Score: N/A (too few clusters)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b27ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Results Summary\n",
    "clustering_results = pd.DataFrame({\n",
    "    'Model': ['K-Means', 'DBSCAN'],\n",
    "    'Clusters': [n_clusters, n_clusters_dbscan],\n",
    "    'Silhouette Score': [kmeans_silhouette, dbscan_silhouette if dbscan_silhouette != -1 else np.nan],\n",
    "    'Noise Points': [0, n_noise]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLUSTERING RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "display(clustering_results)\n",
    "\n",
    "# Visualize cluster distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# K-Means cluster distribution\n",
    "kmeans_counts = pd.Series(kmeans_labels).value_counts().sort_index()\n",
    "axes[0].bar(range(len(kmeans_counts)), kmeans_counts.values, color='steelblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Cluster')\n",
    "axes[0].set_ylabel('Number of Customers')\n",
    "axes[0].set_title(f'K-Means Cluster Distribution (Silhouette: {kmeans_silhouette:.3f})')\n",
    "axes[0].set_xticks(range(len(kmeans_counts)))\n",
    "axes[0].set_xticklabels([f'C{i}' for i in kmeans_counts.index])\n",
    "\n",
    "# DBSCAN cluster distribution\n",
    "dbscan_counts = pd.Series(dbscan_labels).value_counts().sort_index()\n",
    "if -1 in dbscan_counts.index:\n",
    "    # Separate noise from clusters\n",
    "    noise_count = dbscan_counts[-1]\n",
    "    cluster_counts = dbscan_counts[dbscan_counts.index != -1]\n",
    "    x_pos = list(range(len(cluster_counts))) + [len(cluster_counts)]\n",
    "    values = list(cluster_counts.values) + [noise_count]\n",
    "    labels = [f'C{i}' for i in cluster_counts.index] + ['Noise']\n",
    "    colors = ['coral'] * len(cluster_counts) + ['gray']\n",
    "else:\n",
    "    x_pos = range(len(dbscan_counts))\n",
    "    values = dbscan_counts.values\n",
    "    labels = [f'C{i}' for i in dbscan_counts.index]\n",
    "    colors = ['coral'] * len(dbscan_counts)\n",
    "\n",
    "axes[1].bar(x_pos, values, color=colors, alpha=0.7)\n",
    "axes[1].set_xlabel('Cluster')\n",
    "axes[1].set_ylabel('Number of Customers')\n",
    "axes[1].set_title(f'DBSCAN Cluster Distribution (Clusters: {n_clusters_dbscan}, Noise: {n_noise})')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(labels, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef5dac",
   "metadata": {},
   "source": [
    "## 4. Forecasting Models - Traffic Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c469a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare time series data for forecasting\n",
    "print(\"=\" * 60)\n",
    "print(\"FORECASTING MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Detect datetime column\n",
    "datetime_cols = df.select_dtypes(include=['datetime64']).columns\n",
    "if len(datetime_cols) == 0:\n",
    "    # Try to convert\n",
    "    for col in ['TIMESTAMP', 'timestamp', 'date', 'time']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            datetime_cols = [col]\n",
    "            break\n",
    "\n",
    "if len(datetime_cols) > 0:\n",
    "    datetime_col = datetime_cols[0]\n",
    "    print(f\"\\nDatetime column: {datetime_col}\")\n",
    "    \n",
    "    # Find numeric column for forecasting\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    value_col = numeric_cols[0] if len(numeric_cols) > 0 else None\n",
    "    \n",
    "    if value_col:\n",
    "        print(f\"Value column: {value_col}\")\n",
    "        \n",
    "        # Create time series\n",
    "        df[datetime_col] = pd.to_datetime(df[datetime_col])\n",
    "        df_sorted = df.sort_values(datetime_col)\n",
    "        \n",
    "        # Aggregate by datetime\n",
    "        ts_df = df_sorted.groupby(df_sorted[datetime_col].dt.date)[value_col].sum().reset_index()\n",
    "        ts_df.columns = ['ds', 'y']\n",
    "        ts_df['ds'] = pd.to_datetime(ts_df['ds'])\n",
    "        \n",
    "        print(f\"\\nTime series shape: {ts_df.shape}\")\n",
    "        print(f\"Date range: {ts_df['ds'].min()} to {ts_df['ds'].max()}\")\n",
    "        print(f\"Total days: {(ts_df['ds'].max() - ts_df['ds'].min()).days}\")\n",
    "    else:\n",
    "        print(\"No suitable value column found for forecasting\")\n",
    "        ts_df = None\n",
    "else:\n",
    "    print(\"No datetime column found for forecasting\")\n",
    "    ts_df = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ARIMA model (if time series data available)\n",
    "if ts_df is not None and len(ts_df) > 50:\n",
    "    try:\n",
    "        from statsmodels.tsa.arima.model import ARIMA\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 60)\n",
    "        print(\"Training ARIMA...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(ts_df) * 0.8)\n",
    "        train = ts_df[:train_size]['y'].values\n",
    "        test = ts_df[train_size:]['y'].values\n",
    "        \n",
    "        # Fit ARIMA\n",
    "        arima_model = ARIMA(train, order=(1, 1, 1))\n",
    "        arima_fitted = arima_model.fit()\n",
    "        \n",
    "        # Forecast\n",
    "        forecast = arima_fitted.forecast(steps=len(test))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        arima_rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "        arima_mae = mean_absolute_error(test, forecast)\n",
    "        \n",
    "        print(f\"ARIMA RMSE: {arima_rmse:.4f}\")\n",
    "        print(f\"ARIMA MAE: {arima_mae:.4f}\")\n",
    "        \n",
    "        arima_success = True\n",
    "    except Exception as e:\n",
    "        print(f\"ARIMA training failed: {e}\")\n",
    "        arima_success = False\n",
    "        arima_rmse = np.nan\n",
    "        arima_mae = np.nan\n",
    "else:\n",
    "    print(\"Insufficient data for ARIMA forecasting\")\n",
    "    arima_success = False\n",
    "    arima_rmse = np.nan\n",
    "    arima_mae = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Prophet model (if time series data available)\n",
    "if ts_df is not None and len(ts_df) > 50:\n",
    "    try:\n",
    "        from prophet import Prophet\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 60)\n",
    "        print(\"Training Prophet...\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Split data\n",
    "        train_size = int(len(ts_df) * 0.8)\n",
    "        train = ts_df[:train_size].copy()\n",
    "        test = ts_df[train_size:].copy()\n",
    "        \n",
    "        # Fit Prophet\n",
    "        prophet_model = Prophet()\n",
    "        prophet_model.fit(train)\n",
    "        \n",
    "        # Forecast\n",
    "        future = prophet_model.make_future_dataframe(periods=len(test))\n",
    "        forecast_df = prophet_model.predict(future)\n",
    "        \n",
    "        # Get forecasted values for test period\n",
    "        forecasted = forecast_df[-len(test):]['yhat'].values\n",
    "        actual = test['y'].values\n",
    "        \n",
    "        # Calculate metrics\n",
    "        prophet_rmse = np.sqrt(mean_squared_error(actual, forecasted))\n",
    "        prophet_mae = mean_absolute_error(actual, forecasted)\n",
    "        \n",
    "        print(f\"Prophet RMSE: {prophet_rmse:.4f}\")\n",
    "        print(f\"Prophet MAE: {prophet_mae:.4f}\")\n",
    "        \n",
    "        prophet_success = True\n",
    "    except Exception as e:\n",
    "        print(f\"Prophet training failed: {e}\")\n",
    "        prophet_success = False\n",
    "        prophet_rmse = np.nan\n",
    "        prophet_mae = np.nan\n",
    "else:\n",
    "    print(\"Insufficient data for Prophet forecasting\")\n",
    "    prophet_success = False\n",
    "    prophet_rmse = np.nan\n",
    "    prophet_mae = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c852d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting Results Summary\n",
    "if ts_df is not None:\n",
    "    forecasting_results = pd.DataFrame({\n",
    "        'Model': ['ARIMA', 'Prophet'],\n",
    "        'RMSE': [arima_rmse, prophet_rmse],\n",
    "        'MAE': [arima_mae, prophet_mae]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FORECASTING RESULTS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    display(forecasting_results)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # RMSE comparison\n",
    "    rmse_data = forecasting_results[forecasting_results['RMSE'].notna()]\n",
    "    if len(rmse_data) > 0:\n",
    "        axes[0].bar(rmse_data['Model'], rmse_data['RMSE'], \n",
    "                   color=['steelblue', 'coral'], alpha=0.7)\n",
    "        axes[0].set_ylabel('RMSE')\n",
    "        axes[0].set_title('Forecasting Model RMSE Comparison')\n",
    "        for i, v in enumerate(rmse_data['RMSE']):\n",
    "            axes[0].text(i, v + max(rmse_data['RMSE']) * 0.02, f'{v:.2f}', \n",
    "                        ha='center', fontweight='bold')\n",
    "    \n",
    "    # MAE comparison\n",
    "    mae_data = forecasting_results[forecasting_results['MAE'].notna()]\n",
    "    if len(mae_data) > 0:\n",
    "        axes[1].bar(mae_data['Model'], mae_data['MAE'], \n",
    "                   color=['steelblue', 'coral'], alpha=0.7)\n",
    "        axes[1].set_ylabel('MAE')\n",
    "        axes[1].set_title('Forecasting Model MAE Comparison')\n",
    "        for i, v in enumerate(mae_data['MAE']):\n",
    "            axes[1].text(i, v + max(mae_data['MAE']) * 0.02, f'{v:.2f}', \n",
    "                         ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Forecasting models not trained (insufficient time series data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b52a0",
   "metadata": {},
   "source": [
    "## 5. Save Models and Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "MODEL_DIR = project_root / \"models\"\n",
    "RESULTS_DIR = project_root / \"results\"\n",
    "\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "(MODEL_DIR / \"classification\").mkdir(exist_ok=True)\n",
    "(MODEL_DIR / \"clustering\").mkdir(exist_ok=True)\n",
    "(MODEL_DIR / \"forecasting\").mkdir(exist_ok=True)\n",
    "(MODEL_DIR / \"preprocessing\").mkdir(exist_ok=True)\n",
    "\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "(RESULTS_DIR / \"classification\").mkdir(exist_ok=True)\n",
    "(RESULTS_DIR / \"clustering\").mkdir(exist_ok=True)\n",
    "(RESULTS_DIR / \"forecasting\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Saving models and results...\")\n",
    "\n",
    "# Save classification models\n",
    "joblib.dump(rf_model, MODEL_DIR / \"classification\" / \"zone_rf.pkl\")\n",
    "joblib.dump(dt_model, MODEL_DIR / \"classification\" / \"baseline_dt.pkl\")\n",
    "joblib.dump(xgb_model, MODEL_DIR / \"classification\" / \"zone_xgb.pkl\")\n",
    "if 'le' in locals():\n",
    "    joblib.dump(le, MODEL_DIR / \"preprocessing\" / \"encoder.pkl\")\n",
    "print(\"✓ Classification models saved\")\n",
    "\n",
    "# Save clustering models\n",
    "joblib.dump(kmeans_model, MODEL_DIR / \"clustering\" / \"kmeans.pkl\")\n",
    "joblib.dump(dbscan_model, MODEL_DIR / \"clustering\" / \"dbscan.pkl\")\n",
    "joblib.dump(scaler, MODEL_DIR / \"preprocessing\" / \"scaler.pkl\")\n",
    "print(\"✓ Clustering models saved\")\n",
    "\n",
    "# Save forecasting models (if trained)\n",
    "if 'arima_success' in locals() and arima_success:\n",
    "    joblib.dump(arima_fitted, MODEL_DIR / \"forecasting\" / \"arima.pkl\")\n",
    "    print(\"✓ ARIMA model saved\")\n",
    "if 'prophet_success' in locals() and prophet_success:\n",
    "    joblib.dump(prophet_model, MODEL_DIR / \"forecasting\" / \"prophet_model.pkl\")\n",
    "    print(\"✓ Prophet model saved\")\n",
    "\n",
    "# Save results\n",
    "classification_metrics = {\n",
    "    'random_forest': {'accuracy': float(rf_accuracy), 'roc_auc': float(rf_roc_auc)},\n",
    "    'decision_tree': {'accuracy': float(dt_accuracy)},\n",
    "    'xgboost': {'accuracy': float(xgb_accuracy), 'roc_auc': float(xgb_roc_auc)}\n",
    "}\n",
    "\n",
    "clustering_metrics = {\n",
    "    'kmeans': {\n",
    "        'n_clusters': int(n_clusters),\n",
    "        'silhouette_score': float(kmeans_silhouette)\n",
    "    },\n",
    "    'dbscan': {\n",
    "        'n_clusters': int(n_clusters_dbscan),\n",
    "        'silhouette_score': float(dbscan_silhouette) if dbscan_silhouette != -1 else None,\n",
    "        'n_noise': int(n_noise)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / \"classification\" / \"metrics.json\", 'w') as f:\n",
    "    json.dump(classification_metrics, f, indent=2)\n",
    "print(\"✓ Classification metrics saved\")\n",
    "\n",
    "with open(RESULTS_DIR / \"clustering\" / \"silhouette_score.json\", 'w') as f:\n",
    "    json.dump(clustering_metrics, f, indent=2)\n",
    "print(\"✓ Clustering metrics saved\")\n",
    "\n",
    "if ts_df is not None:\n",
    "    forecasting_metrics = {}\n",
    "    if arima_success:\n",
    "        forecasting_metrics['arima'] = {\n",
    "            'rmse': float(arima_rmse),\n",
    "            'mae': float(arima_mae)\n",
    "        }\n",
    "    if prophet_success:\n",
    "        forecasting_metrics['prophet'] = {\n",
    "            'rmse': float(prophet_rmse),\n",
    "            'mae': float(prophet_mae)\n",
    "        }\n",
    "    \n",
    "    if forecasting_metrics:\n",
    "        with open(RESULTS_DIR / \"forecasting\" / \"rmse.json\", 'w') as f:\n",
    "            json.dump(forecasting_metrics, f, indent=2)\n",
    "        print(\"✓ Forecasting metrics saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL MODELS AND RESULTS SAVED!\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401f33c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf8c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODELING EXPERIMENTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. Classification Models:\")\n",
    "print(f\"   - Random Forest: Accuracy = {rf_accuracy:.4f}, ROC-AUC = {rf_roc_auc:.4f}\")\n",
    "print(f\"   - Decision Tree: Accuracy = {dt_accuracy:.4f}\")\n",
    "print(f\"   - XGBoost: Accuracy = {xgb_accuracy:.4f}, ROC-AUC = {xgb_roc_auc:.4f}\")\n",
    "\n",
    "best_classification = max([\n",
    "    ('Random Forest', rf_accuracy),\n",
    "    ('Decision Tree', dt_accuracy),\n",
    "    ('XGBoost', xgb_accuracy)\n",
    "], key=lambda x: x[1])\n",
    "print(f\"   → Best Model: {best_classification[0]} ({best_classification[1]:.4f})\")\n",
    "\n",
    "print(\"\\n2. Clustering Models:\")\n",
    "print(f\"   - K-Means: {n_clusters} clusters, Silhouette = {kmeans_silhouette:.4f}\")\n",
    "print(f\"   - DBSCAN: {n_clusters_dbscan} clusters, Silhouette = {dbscan_silhouette:.4f if dbscan_silhouette != -1 else 'N/A'}\")\n",
    "\n",
    "if ts_df is not None:\n",
    "    print(\"\\n3. Forecasting Models:\")\n",
    "    if arima_success:\n",
    "        print(f\"   - ARIMA: RMSE = {arima_rmse:.4f}, MAE = {arima_mae:.4f}\")\n",
    "    if prophet_success:\n",
    "        print(f\"   - Prophet: RMSE = {prophet_rmse:.4f}, MAE = {prophet_mae:.4f}\")\n",
    "\n",
    "print(\"\\n4. Next Steps:\")\n",
    "print(\"   - Review model performance metrics\")\n",
    "print(\"   - Tune hyperparameters for better performance\")\n",
    "print(\"   - Use models in Streamlit dashboard\")\n",
    "print(\"   - Deploy models via API\")\n",
    "print(\"   - Monitor model performance over time\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Experiments Complete!\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
